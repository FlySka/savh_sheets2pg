# ==========================
# SAVH ETL - Ejemplo de configuración
# ==========================
# Copia este archivo a `.env` y ajusta los valores según tu entorno.
#
# Notas:
# - Usa rutas absolutas o relativas al root del repo (recomendado: relativas).
# - Las variables con formato JSON deben ser JSON válido (comillas dobles, corchetes, etc.).
# - No guardes credenciales reales en repos públicos.

# Excel
# Ruta al archivo Excel fuente (XLSX) que se ingiere.
SAVH_ETL_EXCEL_PATH=./data/BD_SAVH.xlsx

# Selección de hojas (JSON)
# Lista JSON de nombres de hojas a excluir durante la ingesta.
# Ejemplo: ["Hoja1","Hoja2"]
SAVH_ETL_EXCLUDE_SHEETS=[]

# Postgres
# DSN/URL de conexión a Postgres (SQLAlchemy + psycopg).
# Formato: postgresql+psycopg://USUARIO:CLAVE@HOST:PUERTO/DBNAME
SAVH_ETL_PG_DSN=postgresql+psycopg://postgres:postgres@localhost:5432/savh

# Esquema destino para tablas "core" (modelo principal).
SAVH_ETL_PG_SCHEMA_CORE=core
# Esquema destino para tablas de "ingest" (staging/raw).
SAVH_ETL_PG_SCHEMA_INGEST=ingest
# Esquema destino para tablas de auditoría/logs.
SAVH_ETL_PG_SCHEMA_AUDIT=audit

# Orden de aplicación de archivos DDL (JSON)
# Lista JSON con los nombres de los scripts SQL a ejecutar en ese orden.
DEFAULT_DDL_ORDER=["01_schema.sql","02_tables.sql","03_constraints.sql","04_foreign_keys.sql","05_indexes.sql","06_comments.sql","07_triggers.sql"]

# Carga
# Modo de carga de datos:
# - drop_create: recrea estructura/objetos antes de cargar
# - truncate: trunca tablas y recarga
SAVH_ETL_LOAD_MODE=drop_create

# Tamaño de chunk para inserciones/cargas hacia Postgres.
SAVH_ETL_PG_CHUNKSIZE=5000

# General
# Si es true, no escribe cambios (solo simula/valida).
SAVH_ETL_DRY_RUN=false

# Si es true, ejecuta solo DDL (creación de esquema/tablas) y no carga datos.
SAVH_ETL_ONLY_DDL=false

# Nivel de logging (por ejemplo: DEBUG, INFO, WARNING, ERROR).
SAVH_ETL_LOG_LEVEL=INFO
